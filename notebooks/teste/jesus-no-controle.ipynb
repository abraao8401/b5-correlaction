{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8dc145-deeb-43a8-8e5a-788485c87a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: moviepy in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (2.1.2)\n",
      "Requirement already satisfied: openai-whisper in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (20240930)\n",
      "Requirement already satisfied: torch in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (0.21.0)\n",
      "Requirement already satisfied: transformers in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (4.49.0)\n",
      "Requirement already satisfied: xgboost in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: imbalanced-learn in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (0.12.4)\n",
      "Requirement already satisfied: pandas in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from moviepy) (5.1.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from moviepy) (1.0.1)\n",
      "Requirement already satisfied: pillow<11.0,>=9.2.0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from moviepy) (10.4.0)\n",
      "Requirement already satisfied: numba in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: tqdm in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: more-itertools in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from openai-whisper) (10.6.0)\n",
      "Requirement already satisfied: tiktoken in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: triton>=2.0.0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from openai-whisper) (3.2.0)\n",
      "Requirement already satisfied: filelock in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: scipy in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from imbalanced-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python moviepy openai-whisper torch torchvision transformers xgboost imbalanced-learn pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5538d1-ffd5-4e45-87a8-81986e459791",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4f9ad9-d439-49cd-a570-e69c15df0e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1751603475.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    export TOKENIZERS_PARALLELISM=false\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import whisper\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Configurações\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VIDEO_DIR = \"data/dataset/videos\"\n",
    "DATASET_PATH = \"data/dataset_final.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac744ec-856e-47f8-8622-28f7e686ca11",
   "metadata": {},
   "source": [
    "## Processamento de Vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838ee029-82ed-479d-93c2-9c5f6794a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import clip\n",
    "\n",
    "def extract_frames(video_path, frame_rate=1):\n",
    "    \"\"\"Extrai frames de um vídeo usando OpenCV\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(fps / frame_rate)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if len(frames) % frame_interval == 0:\n",
    "            frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def transcribe_audio(video_path):\n",
    "    \"\"\"Transcreve áudio com Whisper\"\"\"\n",
    "    model = whisper.load_model(\"base\", device=DEVICE)\n",
    "    result = model.transcribe(video_path)\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374127c-a369-4734-9101-9f71b895e9bd",
   "metadata": {},
   "source": [
    "## Extração de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3709950-8a57-4f24-952e-22f5cb49937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def get_visual_embeddings(frames):\n",
    "    \"\"\"Gera embeddings visuais com CLIP e projeta para o espaço de 768 dimensões\"\"\"\n",
    "    model, preprocess = clip.load(\"ViT-B/32\", device=DEVICE)\n",
    "    embeddings = []\n",
    "    \n",
    "    for frame in frames:\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(frame_rgb)\n",
    "        image_tensor = preprocess(pil_image).unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embedding = model.encode_image(image_tensor)\n",
    "            embeddings.append(embedding.cpu().numpy().squeeze())\n",
    "    \n",
    "    # Média dos embeddings dos frames\n",
    "    visual_embedding = np.mean(embeddings, axis=0)\n",
    "    \n",
    "    # Projeção para 768 dimensões\n",
    "    projection_layer = nn.Linear(512, 768)\n",
    "    visual_embedding = torch.tensor(visual_embedding).unsqueeze(0).to(DEVICE)\n",
    "    visual_embedding = projection_layer(visual_embedding).squeeze()\n",
    "    \n",
    "    # Desanexa o tensor e move para a CPU antes de converter para NumPy\n",
    "    visual_embedding_np = visual_embedding.detach().cpu().numpy()\n",
    "    \n",
    "    return visual_embedding_np\n",
    "\n",
    "\n",
    "\n",
    "def get_text_embeddings_bert(text, model_name='neuralmind/bert-base-portuguese-cased'):\n",
    "    \"\"\"Gera embeddings textuais com BERT\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4cfed78-492c-4b67-b57f-6accf36aa0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista de vídeos\n",
    "videos = [\n",
    "    (\"modified_Video1.mp4\", 0),\n",
    "    (\"modified_Video8.mp4\", 0)\n",
    "]\n",
    "\n",
    "# Adiciona os 13 vídeos originais (target 1)\n",
    "for i in range(2, 16):\n",
    "    if i != 8:  # Pula o vídeo 8, já que ele está na lista de modificados\n",
    "        videos.append((f\"Video{i}.mp4\", 1))\n",
    "\n",
    "# Cria DataFrame\n",
    "df = pd.DataFrame(videos, columns=[\"video_path\", \"target\"])\n",
    "\n",
    "# Salva o CSV\n",
    "df.to_csv(\"data/dataset/metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d04f7b3-a529-4c73-800a-166676f35855",
   "metadata": {},
   "source": [
    "## Carregamento de metadados com target (Luan analise essa parte para combinar com a extracão de embbedings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e318094d-119d-4cbf-bc09-57b36417a569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em processamento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraao/anaconda3/envs/multimodal-env/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "AUC-ROC: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Carrega metadados (rótulos manuais)\n",
    "metadata = pd.read_csv(\"data/dataset/metadata.csv\")  # Arquivo com colunas: [video_path, target]\n",
    "\n",
    "# Processa cada vídeo\n",
    "all_data = []\n",
    "\n",
    "for idx, row in metadata.iterrows():\n",
    "    video_path = os.path.join(VIDEO_DIR, row[\"video_path\"])\n",
    "    \n",
    "    # Processamento de vídeo\n",
    "    frames = extract_frames(video_path)\n",
    "    visual_embedding = get_visual_embeddings(frames)\n",
    "    \n",
    "    # Processamento de áudio\n",
    "    transcription = transcribe_audio(video_path)\n",
    "    text_embedding = get_text_embeddings_bert(transcription)\n",
    "    \n",
    "    # Combina embeddings\n",
    "    combined = np.concatenate([visual_embedding, text_embedding])\n",
    "    all_data.append({\n",
    "        \"features\": combined,\n",
    "        \"target\": row[\"target\"]\n",
    "    })\n",
    "\n",
    "    print(\"Em processamento\")\n",
    "\n",
    "# Cria DataFrame final\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Duplica os vídeos falsos até ter pelo menos 5 amostras\n",
    "false_samples = df[df['target'] == 0]\n",
    "df = pd.concat([df, false_samples.sample(5, replace=True)])\n",
    "\n",
    "\n",
    "X = np.vstack(df[\"features\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Balanceamento com SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Treino-Teste Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "\n",
    "# Treina XGBoost\n",
    "model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliação\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Ajuste de Threshold (Opcional)\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "optimal_threshold = 0.4  # Definir via curva ROC\n",
    "y_pred_adj = (y_probs > optimal_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c7cfd8-f2fc-4d91-a269-424730e3ed20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12142bb-37df-4ada-a541-3b7336f6a1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7118db5-5f08-45df-a8bd-53fa2bd97597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (multimodal-env)",
   "language": "python",
   "name": "multimodal-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
